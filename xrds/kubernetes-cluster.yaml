# resource "aws_eks_cluster" "cluster" {
#    name                      = lower(format("%s", var.cluster_name))
#    version                   = var.cluster_version
#    enabled_cluster_log_types = var.cluster_log_types
#
#    role_arn = aws_iam_role.cluster-iam-role.arn
#
#    access_config {
#        authentication_mode                         = "API_AND_CONFIG_MAP"
#        bootstrap_cluster_creator_admin_permissions = false
#    }
#
#    vpc_config {
#        security_group_ids = [
#            aws_security_group.cluster.id
#        ]
#
#        subnet_ids              = var.cluster_private_subnet_ids
#        endpoint_private_access = true
#        endpoint_public_access  = false
#    }
#
#    kubernetes_network_config {
#        ip_family = "ipv4"
#    }
#
#    timeouts {
#        create = lookup(var.cluster_timeouts, "create", null)
#        update = lookup(var.cluster_timeouts, "update", null)
#        delete = lookup(var.cluster_timeouts, "delete", null)
#    }
#
#    depends_on = [
#        aws_iam_role_policy_attachment.cluster-iam-policy-attachment,
#        aws_security_group_rule.cluster-group-rule-outbound,
#        aws_security_group_rule.cluster-group-rule,
#    ]
#
#    tags = merge({
#        Name = lower(format("%s", var.cluster_name))
#    }, local.tags)
#}
---
apiVersion: eks.aws.upbound.io/v1beta1
kind: Cluster
metadata:
    name: eks-cluster-pia
spec:
    deletionPolicy: Delete
    forProvider:
        region: us-east-2
        roleArnRef:
            name: ""
        version: "1.29"

        enabledClusterLogTypes: ["audit", "api", "authenticator", "controllerManager", "scheduler"]
        #roleArnSelector:
        #    matchLabels:
        #        testing.upbound.io/example-name: example-pia
        kubernetesNetworkConfig:
            -   - ipFamily: ipv4
        vpcConfig:
            - { endpointPrivateAccess: true, endpointPublicAccess: true, securityGroupIdRefs: [ { name: "" } ], subnetIdRefs: [ { name: sample-subnet1 }, { name: sample-subnet2 } ] }
